{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3., 4., 5., 6., 7.],\n",
       "        [3., 5., 6., 7., 8., 4., 5.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.FloatTensor([[1,2,3,4,5,6,7],[3,5,6,7,8,4,5]])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 3.],\n",
       "         [2., 5.],\n",
       "         [3., 6.],\n",
       "         [4., 7.],\n",
       "         [5., 8.],\n",
       "         [6., 4.],\n",
       "         [7., 5.]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.unfold(0,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_filter_1 = torch.tensor([[1.0,2,1],[2,4,5],[6,7,8]])\n",
    "mock_filter_2 = torch.tensor([[1.0,6,7],[1,9,5],[4,7,8]])\n",
    "mock_filter_3 = torch.tensor([[1.0,3,1],[7,0,5],[9,7,0]])\n",
    "mock_filter_4 = torch.tensor([[3.0,2,4],[0,4,5],[1,7,0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_filter_combined = torch.stack([mock_filter_1, mock_filter_2, mock_filter_3, mock_filter_4]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_filter_combined = torch.stack([mock_filter_combined, mock_filter_combined], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 3])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_filter_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1., 2., 1.],\n",
      "         [2., 4., 5.],\n",
      "         [6., 7., 8.]],\n",
      "\n",
      "        [[1., 2., 1.],\n",
      "         [2., 4., 5.],\n",
      "         [6., 7., 8.]]])\n",
      "tensor([[[1., 6., 7.],\n",
      "         [1., 9., 5.],\n",
      "         [4., 7., 8.]],\n",
      "\n",
      "        [[1., 6., 7.],\n",
      "         [1., 9., 5.],\n",
      "         [4., 7., 8.]]])\n",
      "tensor([[[1., 3., 1.],\n",
      "         [7., 0., 5.],\n",
      "         [9., 7., 0.]],\n",
      "\n",
      "        [[1., 3., 1.],\n",
      "         [7., 0., 5.],\n",
      "         [9., 7., 0.]]])\n",
      "tensor([[[3., 2., 4.],\n",
      "         [0., 4., 5.],\n",
      "         [1., 7., 0.]],\n",
      "\n",
      "        [[3., 2., 4.],\n",
      "         [0., 4., 5.],\n",
      "         [1., 7., 0.]]])\n"
     ]
    }
   ],
   "source": [
    "print(mock_filter_combined[0])\n",
    "print(mock_filter_combined[1])\n",
    "print(mock_filter_combined[2])\n",
    "print(mock_filter_combined[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_groups = mock_filter_combined.unfold(0, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 3, 2])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_groups.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 2., 1.],\n",
       "          [2., 4., 5.],\n",
       "          [6., 7., 8.]],\n",
       "\n",
       "         [[1., 2., 1.],\n",
       "          [2., 4., 5.],\n",
       "          [6., 7., 8.]]],\n",
       "\n",
       "\n",
       "        [[[1., 6., 7.],\n",
       "          [1., 9., 5.],\n",
       "          [4., 7., 8.]],\n",
       "\n",
       "         [[1., 6., 7.],\n",
       "          [1., 9., 5.],\n",
       "          [4., 7., 8.]]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_groups[0].permute(3,0,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 3., 1.],\n",
       "          [7., 0., 5.],\n",
       "          [9., 7., 0.]],\n",
       "\n",
       "         [[1., 3., 1.],\n",
       "          [7., 0., 5.],\n",
       "          [9., 7., 0.]]],\n",
       "\n",
       "\n",
       "        [[[3., 2., 4.],\n",
       "          [0., 4., 5.],\n",
       "          [1., 7., 0.]],\n",
       "\n",
       "         [[3., 2., 4.],\n",
       "          [0., 4., 5.],\n",
       "          [1., 7., 0.]]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter_groups[1].permute(3,0,1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 2, 3, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filters = mock_filter_combined\n",
    "filters.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2,2,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "activations = F.conv2d(inputs,filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 4, 2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-9.9850e-02,  4.6968e-01,  2.6587e-01,  1.5696e+00],\n",
       "          [-5.0539e-01, -7.3806e-02,  1.2739e-02,  1.0668e+00],\n",
       "          [-3.6673e-01,  4.1080e-01, -7.1179e-02,  5.8535e-02],\n",
       "          [-4.4407e-01, -1.4111e+00, -2.8855e-01,  3.2753e-01]],\n",
       "\n",
       "         [[-9.2353e-01,  3.5978e-01, -6.4503e-01, -4.1743e-01],\n",
       "          [ 9.7220e-01,  1.6586e+00,  3.8452e-01,  2.3972e-01],\n",
       "          [ 1.0739e+00, -7.3287e-01, -2.6750e-01,  5.0841e-01],\n",
       "          [ 8.9542e-01, -1.0102e+00, -1.1399e+00,  1.9715e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.5995e+00,  6.3038e-01,  2.7255e+00, -4.4879e-01],\n",
       "          [-1.3059e-01,  2.4321e+00,  3.9858e-01, -1.8686e-01],\n",
       "          [-1.3590e+00,  1.2190e+00, -1.4175e-01, -7.9056e-01],\n",
       "          [ 1.8291e+00, -2.0615e-01,  1.1696e+00, -2.2797e+00]],\n",
       "\n",
       "         [[-2.0379e+00,  1.9073e+00, -1.0902e+00, -1.6716e+00],\n",
       "          [-9.0178e-01,  1.6256e+00,  5.7807e-01, -2.1041e-01],\n",
       "          [-8.7855e-01,  1.8043e-03,  4.5222e-01, -1.1819e-01],\n",
       "          [-4.2819e-01, -6.4969e-01,  1.9479e+00, -4.4059e-01]]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  8.7945,  12.7468],\n",
       "          [-23.2027, -15.8082]],\n",
       "\n",
       "         [[ 15.8802,  19.1888],\n",
       "          [-17.7002,  -2.9088]],\n",
       "\n",
       "         [[ 10.4498,  13.2008],\n",
       "          [ -4.0120, -27.1280]],\n",
       "\n",
       "         [[  3.8503,  11.7674],\n",
       "          [-13.3205,  -0.1658]]],\n",
       "\n",
       "\n",
       "        [[[ 22.9261,  15.9519],\n",
       "          [ 37.3751,  -0.3215]],\n",
       "\n",
       "         [[ 68.6843,   8.1547],\n",
       "          [ 65.0060,   3.2447]],\n",
       "\n",
       "         [[ -5.1254,  44.9018],\n",
       "          [  4.6241,  24.7128]],\n",
       "\n",
       "         [[ 37.7237,   7.7164],\n",
       "          [ 10.7707,  30.2024]]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = torch.split(activations, 2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[  8.7945,  12.7468],\n",
       "           [-23.2027, -15.8082]],\n",
       " \n",
       "          [[ 15.8802,  19.1888],\n",
       "           [-17.7002,  -2.9088]]],\n",
       " \n",
       " \n",
       "         [[[ 22.9261,  15.9519],\n",
       "           [ 37.3751,  -0.3215]],\n",
       " \n",
       "          [[ 68.6843,   8.1547],\n",
       "           [ 65.0060,   3.2447]]]]), tensor([[[[ 10.4498,  13.2008],\n",
       "           [ -4.0120, -27.1280]],\n",
       " \n",
       "          [[  3.8503,  11.7674],\n",
       "           [-13.3205,  -0.1658]]],\n",
       " \n",
       " \n",
       "         [[[ -5.1254,  44.9018],\n",
       "           [  4.6241,  24.7128]],\n",
       " \n",
       "          [[ 37.7237,   7.7164],\n",
       "           [ 10.7707,  30.2024]]]]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[  8.7945,  12.7468],\n",
       "          [-23.2027, -15.8082]],\n",
       "\n",
       "         [[ 15.8802,  19.1888],\n",
       "          [-17.7002,  -2.9088]]],\n",
       "\n",
       "\n",
       "        [[[ 22.9261,  15.9519],\n",
       "          [ 37.3751,  -0.3215]],\n",
       "\n",
       "         [[ 68.6843,   8.1547],\n",
       "          [ 65.0060,   3.2447]]]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another test case where filtere are not divisible by the number of groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_filter_1 = torch.tensor([[1.0,2,1],[2,4,5],[6,7,8]])\n",
    "mock_filter_2 = torch.tensor([[1.0,6,7],[1,9,5],[4,7,8]])\n",
    "mock_filter_3 = torch.tensor([[1.0,3,1],[7,0,5],[9,7,0]])\n",
    "mock_filter_4 = torch.tensor([[3.0,2,4],[0,4,5],[1,7,0]])\n",
    "mock_filter_5 = torch.tensor([[3.0,2,4],[0,4,5],[1,7,0]])\n",
    "mock_filter_6 = torch.tensor([[3.0,2,5],[1,8,0],[2,5,8]])\n",
    "mock_filter_7 = torch.tensor([[4.0,6,9],[0,0,5],[1,3,7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "mock_filter_combined = torch.stack([mock_filter_1, mock_filter_2, mock_filter_3, mock_filter_4,mock_filter_5,\n",
    "                                   mock_filter_6, mock_filter_7]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 2, 3, 3])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_filter_combined = torch.stack([mock_filter_combined, mock_filter_combined], dim=1)\n",
    "mock_filter_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2,2,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 2, 2])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = F.conv2d(inputs,mock_filter_combined)\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 3.8571e-01,  1.5037e+00,  8.7711e-01, -9.7449e-01],\n",
       "          [-5.8401e-01, -5.8842e-01, -1.0952e+00, -1.6888e+00],\n",
       "          [-2.2338e-01,  1.9856e-01,  1.7527e+00,  6.1884e-01],\n",
       "          [ 1.1804e+00, -1.1167e+00,  5.7511e-01,  2.2623e+00]],\n",
       "\n",
       "         [[ 2.2318e+00,  2.4331e-01,  3.6069e-01,  1.6768e+00],\n",
       "          [ 5.6614e-01,  1.5589e+00,  5.7866e-01,  7.4887e-01],\n",
       "          [-2.3629e-01,  1.6206e-01,  1.0245e+00,  5.0072e-01],\n",
       "          [ 6.9069e-01, -6.2059e-01,  6.0690e-01, -3.9473e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 1.1432e+00, -4.1473e-01,  5.8279e-01, -1.5270e-01],\n",
       "          [ 1.6269e-03,  1.5814e-01,  8.7467e-01, -1.1829e+00],\n",
       "          [ 1.3435e-01,  1.4104e+00,  1.0563e+00, -6.8253e-02],\n",
       "          [-2.0916e-01,  1.9054e+00,  8.8494e-01, -1.1731e+00]],\n",
       "\n",
       "         [[ 9.4696e-01, -2.9829e-01,  1.5971e+00,  5.7616e-01],\n",
       "          [ 4.8528e-01, -1.4352e+00,  1.2214e+00,  1.4739e+00],\n",
       "          [-6.7575e-01,  2.0031e+00, -4.7757e-01, -1.1840e-03],\n",
       "          [ 1.6427e-01,  1.6352e+00,  3.6093e-01, -3.4280e-01]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[30.5966, 30.6605],\n",
       "          [24.3373, 29.2164]],\n",
       "\n",
       "         [[50.8009, 35.5511],\n",
       "          [23.6404, 38.5105]],\n",
       "\n",
       "         [[ 4.7757, 30.9422],\n",
       "          [17.7242, -0.7584]],\n",
       "\n",
       "         [[19.6616, 23.5610],\n",
       "          [ 4.8597, 21.3619]],\n",
       "\n",
       "         [[19.6616, 23.5610],\n",
       "          [ 4.8597, 21.3619]],\n",
       "\n",
       "         [[48.3828, 31.6299],\n",
       "          [ 6.2416, 37.1330]],\n",
       "\n",
       "         [[49.5723, 32.5651],\n",
       "          [19.9215, 12.8028]]],\n",
       "\n",
       "\n",
       "        [[[34.4659, 35.3320],\n",
       "          [49.9759, 29.8387]],\n",
       "\n",
       "         [[38.9041, 51.5231],\n",
       "          [75.1428, 32.3679]],\n",
       "\n",
       "         [[35.0414, 33.5382],\n",
       "          [22.2364, 69.4363]],\n",
       "\n",
       "         [[42.2892, 21.2186],\n",
       "          [48.5784, 15.7545]],\n",
       "\n",
       "         [[42.2892, 21.2186],\n",
       "          [48.5784, 15.7545]],\n",
       "\n",
       "         [[26.6290, 28.9950],\n",
       "          [63.7339, 11.0429]],\n",
       "\n",
       "         [[47.9325, 20.1572],\n",
       "          [35.3421,  6.4070]]]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[30.5966, 30.6605],\n",
       "           [24.3373, 29.2164]],\n",
       " \n",
       "          [[50.8009, 35.5511],\n",
       "           [23.6404, 38.5105]]],\n",
       " \n",
       " \n",
       "         [[[34.4659, 35.3320],\n",
       "           [49.9759, 29.8387]],\n",
       " \n",
       "          [[38.9041, 51.5231],\n",
       "           [75.1428, 32.3679]]]]), tensor([[[[ 4.7757, 30.9422],\n",
       "           [17.7242, -0.7584]],\n",
       " \n",
       "          [[19.6616, 23.5610],\n",
       "           [ 4.8597, 21.3619]]],\n",
       " \n",
       " \n",
       "         [[[35.0414, 33.5382],\n",
       "           [22.2364, 69.4363]],\n",
       " \n",
       "          [[42.2892, 21.2186],\n",
       "           [48.5784, 15.7545]]]]), tensor([[[[19.6616, 23.5610],\n",
       "           [ 4.8597, 21.3619]],\n",
       " \n",
       "          [[48.3828, 31.6299],\n",
       "           [ 6.2416, 37.1330]]],\n",
       " \n",
       " \n",
       "         [[[42.2892, 21.2186],\n",
       "           [48.5784, 15.7545]],\n",
       " \n",
       "          [[26.6290, 28.9950],\n",
       "           [63.7339, 11.0429]]]]), tensor([[[[49.5723, 32.5651],\n",
       "           [19.9215, 12.8028]]],\n",
       " \n",
       " \n",
       "         [[[47.9325, 20.1572],\n",
       "           [35.3421,  6.4070]]]])]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groups = torch.split(activations, 2, dim=1)\n",
    "list(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupwise_mean = [torch.mean(groups[i]) for i in range(0,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(38.1790), tensor(25.6388)]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupwise_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(13.0969), tensor(17.7281)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "groupwise_std = [torch.std(groups[i]) for i in range(0,2)]\n",
    "groupwise_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test channelwise receptive field calcualtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_receptive_field_layer_no_batch_norm(feature_maps, linear_map_param_1, \n",
    "                                                  linear_map_param_2):\n",
    "    number_of_maps = feature_maps[1]\n",
    "    std_map_wise = feature_maps.transpose(0,1).contiguous().view(number_of_maps, -1).std(1)\n",
    "    receptive_fields = feature_maps.transpose(1,3).div(std_map_wise).transpose(1,3)\n",
    "    receptive_fields = torch.sigmoid(linear_map_param_1 * receptive_fields + linear_map_param_2)\n",
    "    return receptive_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "calculate_receptive_field_layer_no_batch_norm() missing 2 required positional arguments: 'linear_map_param_1' and 'linear_map_param_2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-755dd229b2d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcalculate_receptive_field_layer_no_batch_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: calculate_receptive_field_layer_no_batch_norm() missing 2 required positional arguments: 'linear_map_param_1' and 'linear_map_param_2'"
     ]
    }
   ],
   "source": [
    "calculate_receptive_field_layer_no_batch_norm(activations)\n",
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=activations.transpose(0,1)\n",
    "print(kk.shape)\n",
    "c =kk.contiguous().view(5, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = torch.mean(c,1)\n",
    "c.std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(activations)\n",
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kk=activations.transpose(1,3)\n",
    "print(kk)\n",
    "print(kk.shape)\n",
    "activations.transpose(1,3).div(torch.Tensor([0.1,1,1,1,1])).transpose(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_fields = 2.0 * activations + 1.0\n",
    "print(receptive_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_fields = torch.sigmoid(receptive_fields)\n",
    "print(receptive_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_fields.shape\n",
    "receptive_fields= receptive_fields.transpose(1, 3).add(torch.Tensor([0.1,1,1,1,2])).transpose(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(receptive_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(receptive_fields.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = torch.split(activations, 2, dim=1)\n",
    "groups = list(groups)\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test regularizer on activations in layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculate the numerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(groups[0].shape)\n",
    "print(groups[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_tensor = torch.sub(groups[0], groups[0][0][0])\n",
    "difference_tensor_2 = torch.sub(groups[1], groups[1][0][0])\n",
    "print(difference_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(difference_tensor.norm(1))\n",
    "print(difference_tensor_2.norm(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.empty(2)\n",
    "l1_norms = torch.zeros_like(input)\n",
    "batch_size = 2\n",
    "for i in range(0, 2):\n",
    "    current_group = groups[i]\n",
    "    norm = torch.zeros(1)\n",
    "    \n",
    "    for j in range(0, 2):\n",
    "        difference_tensor = torch.sub(current_group[j], current_group[j][0])\n",
    "        print(difference_tensor)\n",
    "        norm = norm  + difference_tensor.norm(1)\n",
    "    \n",
    "    #difference_tensor = torch.sub(current_group, current_group[0][0])\n",
    "    l1_norms[i] = norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "current_group[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate with denominator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2, 2])\n",
      "(tensor([[[[30.5966, 30.6605],\n",
      "          [24.3373, 29.2164]],\n",
      "\n",
      "         [[50.8009, 35.5511],\n",
      "          [23.6404, 38.5105]]],\n",
      "\n",
      "\n",
      "        [[[34.4659, 35.3320],\n",
      "          [49.9759, 29.8387]],\n",
      "\n",
      "         [[38.9041, 51.5231],\n",
      "          [75.1428, 32.3679]]]]), tensor([[[[ 4.7757, 30.9422],\n",
      "          [17.7242, -0.7584]],\n",
      "\n",
      "         [[19.6616, 23.5610],\n",
      "          [ 4.8597, 21.3619]]],\n",
      "\n",
      "\n",
      "        [[[35.0414, 33.5382],\n",
      "          [22.2364, 69.4363]],\n",
      "\n",
      "         [[42.2892, 21.2186],\n",
      "          [48.5784, 15.7545]]]]), tensor([[[[19.6616, 23.5610],\n",
      "          [ 4.8597, 21.3619]],\n",
      "\n",
      "         [[48.3828, 31.6299],\n",
      "          [ 6.2416, 37.1330]]],\n",
      "\n",
      "\n",
      "        [[[42.2892, 21.2186],\n",
      "          [48.5784, 15.7545]],\n",
      "\n",
      "         [[26.6290, 28.9950],\n",
      "          [63.7339, 11.0429]]]]), tensor([[[[49.5723, 32.5651],\n",
      "          [19.9215, 12.8028]]],\n",
      "\n",
      "\n",
      "        [[[47.9325, 20.1572],\n",
      "          [35.3421,  6.4070]]]]))\n"
     ]
    }
   ],
   "source": [
    "print(groups[0].shape)\n",
    "print(groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [20.2044,  4.8905, -0.6969,  9.2941]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 4.4382, 16.1910, 25.1669,  2.5293]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [ 14.8858,  -7.3813, -12.8645,  22.1204]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  7.2477, -12.3195,  26.3419, -53.6818]])\n"
     ]
    }
   ],
   "source": [
    "input = torch.empty(2)\n",
    "l1_norms = torch.zeros_like(input)\n",
    "for i in range(0, 2):\n",
    "    current_group = groups[i]\n",
    "    # print(current_group.size())\n",
    "    current_norm = torch.zeros(1)\n",
    "    for j in range(0, 2):\n",
    "        current_map_set = current_group[j]  \n",
    "        print(current_map_set.shape)\n",
    "        num = current_group.size(0)\n",
    "        # print(num)\n",
    "        sub_tensor = current_map_set.contiguous().view(num, -1)\n",
    "        # print(sub_tensor.shape)\n",
    "        sub_tensor_2 = current_map_set[0].view(-1,4)\n",
    "        # print(sub_tensor_2.shape)\n",
    "        difference_tensor = torch.sub(sub_tensor, sub_tensor_2)\n",
    "        print(difference_tensor)\n",
    "        num_tensor = difference_tensor.norm(1, dim=1)\n",
    "        denom_tensor = torch.add(sub_tensor.norm(1, dim=1), sub_tensor_2.norm(1))\n",
    "        value_tensor = torch.div(num_tensor, denom_tensor).norm(1)\n",
    "        current_norm = current_norm + value_tensor\n",
    "    l1_norms[i] = current_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-20.2044,  -4.8905,   0.6969,  -9.2941],\n",
      "        [ -4.4382, -16.1910, -25.1669,  -2.5293]])\n",
      "tensor([[-28.7212,  -8.0689,  -1.3820, -15.7711],\n",
      "        [ 15.6602,  -7.7763, -15.1555,   4.7117]])\n",
      "tensor([0.1198, 0.1811], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "number_of_groups = 2\n",
    "maps_per_group = int(len(activations[1]) / number_of_groups)\n",
    "activation_groups = torch.split(activations, maps_per_group, dim=1)\n",
    "activation_groups = list(activation_groups)\n",
    "input = torch.empty(2)\n",
    "groupwise_activation_norms = torch.zeros_like(input).cuda()\n",
    "num_random_pairs = 2\n",
    "\n",
    "for i in range(0, 2):\n",
    "    current_group = activation_groups[i]\n",
    "    batch_size = current_group.shape[0]\n",
    "    num_of_filters = current_group.shape[1]\n",
    "    random_map_indices = random.sample(range(0, num_of_filters), num_random_pairs)\n",
    "    random_map_indices = torch.LongTensor(random_map_indices)\n",
    "    selected_pairs = torch.index_select(current_group, 1, random_map_indices)\n",
    "    selected_pair_groups = torch.split(selected_pairs, num_random_pairs//2, dim=1)\n",
    "    selected_pair_groups = list(selected_pair_groups)\n",
    "    difference_tensor = torch.sub(selected_pair_groups[0], selected_pair_groups[1])\n",
    "    difference_tensor = difference_tensor.contiguous().view(-1,\n",
    "                                                            difference_tensor.shape[2] *\n",
    "                                                            difference_tensor.shape[3])\n",
    "    print(difference_tensor)\n",
    "    num_tensor_norm = difference_tensor.norm(1, dim=1)\n",
    "    selected_pair_groups[0] = selected_pair_groups[0].view(-1,\n",
    "                                                       selected_pair_groups[0].shape[2]*\n",
    "                                                       selected_pair_groups[0].shape[3])\n",
    "    selected_pair_groups[1] = selected_pair_groups[1].view(-1,\n",
    "                                                       selected_pair_groups[1].shape[2]*\n",
    "                                                       selected_pair_groups[1].shape[3])\n",
    "    \n",
    "    denom_tensor_norm = torch.add(selected_pair_groups[0].norm(1, dim=1),\n",
    "                             selected_pair_groups[1].norm(1, dim=1))\n",
    "    \n",
    "    denom_tensor_norm = torch.add(denom_tensor_norm, num_tensor_norm)\n",
    "    iou_map_wise = torch.div(2 * num_tensor_norm, denom_tensor_norm)\n",
    "    iou_map_wise = torch.div(iou_map_wise, num_random_pairs)\n",
    "    groupwise_activation_norms[i] = torch.div(iou_map_wise.norm(1), batch_size)\n",
    "    \n",
    "print(groupwise_activation_norms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[35.0414, 33.5382, 22.2364, 69.4363],\n",
      "        [42.2892, 21.2186, 48.5784, 15.7545]])\n"
     ]
    }
   ],
   "source": [
    "print(sub_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([320.5047, 288.0931])\n"
     ]
    }
   ],
   "source": [
    "print(denom_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0000, 99.5910])\n"
     ]
    }
   ],
   "source": [
    "print(num_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2723, 0.8087])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2723, 0.8087])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l1_norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-28.7212,  -8.0689,  -1.3820, -15.7711],\n",
       "        [ 15.6602,  -7.7763, -15.1555,   4.7117]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([53.9432, 43.3037])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_tensor.norm(1, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation regularizer across a pair of layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 3, 3])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# our first set of activations are : <activations>\n",
    "#create second set of activations\n",
    "inputs = torch.randn(2,2,5,5)\n",
    "activations_set2 = F.conv2d(inputs,mock_filter_combined)\n",
    "activations_set2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "print(activations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_per_group = int(len(activations_set2[1]) / 2)\n",
    "#print(maps_per_group)\n",
    "activation_groups = torch.split(activations_set2, 2, dim=1)\n",
    "activation_groups = list(activation_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[-17.7008,  -5.8641,  23.5794],\n",
       "           [ 27.1721,  28.8436,  26.9284],\n",
       "           [ -9.5199,  12.0156,  -5.4923]],\n",
       " \n",
       "          [[-12.1438, -10.9801,  11.9130],\n",
       "           [ 21.8212,  15.5175,  45.1714],\n",
       "           [  1.3837,  26.1816,   4.3394]]],\n",
       " \n",
       " \n",
       "         [[[ 21.4104,  -2.6072, -24.6902],\n",
       "           [  4.2356,   8.6019, -16.2357],\n",
       "           [ 12.1759,  29.9097, -10.7793]],\n",
       " \n",
       "          [[ 33.2310,  -4.9027, -39.5759],\n",
       "           [ 20.0659,   8.0390, -38.4173],\n",
       "           [ 23.6363,  19.9502, -17.5341]]]]),\n",
       " tensor([[[[-28.5190, -18.6493,  23.7312],\n",
       "           [ 10.5411,  32.0266,  19.4209],\n",
       "           [ -6.1077,   6.7046,  12.1338]],\n",
       " \n",
       "          [[-10.0317, -14.7439,  20.7129],\n",
       "           [  6.5238,  17.4036,  20.1796],\n",
       "           [ 19.0229,  -6.5880,  15.1647]]],\n",
       " \n",
       " \n",
       "         [[[  8.7467,  23.7068, -17.3820],\n",
       "           [ -7.8498,   7.1619,   9.8824],\n",
       "           [  5.4073,  12.1971,   4.6697]],\n",
       " \n",
       "          [[ 19.6418,   5.8681, -28.3233],\n",
       "           [  9.8211,  -2.8661,  -9.8595],\n",
       "           [ 14.7343,   1.7130,   9.0871]]]]),\n",
       " tensor([[[[-10.0317, -14.7439,  20.7129],\n",
       "           [  6.5238,  17.4036,  20.1796],\n",
       "           [ 19.0229,  -6.5880,  15.1647]],\n",
       " \n",
       "          [[ -9.8524,   1.0061,  -2.3018],\n",
       "           [ 14.5721,   3.8963,  35.9803],\n",
       "           [ -6.1578,  23.3687,  -4.1296]]],\n",
       " \n",
       " \n",
       "         [[[ 19.6418,   5.8681, -28.3233],\n",
       "           [  9.8211,  -2.8661,  -9.8595],\n",
       "           [ 14.7343,   1.7130,   9.0871]],\n",
       " \n",
       "          [[ 25.3196,  -8.2169, -22.5696],\n",
       "           [ 12.3211,  18.3388, -32.0511],\n",
       "           [ 12.1168,  18.8864,  -4.0852]]]]),\n",
       " tensor([[[[ -5.4429, -11.4485,  22.5679],\n",
       "           [ 16.1082,  -1.1937,  34.8856],\n",
       "           [-16.2182,   8.5221,   8.8133]]],\n",
       " \n",
       " \n",
       "         [[[ 20.7010, -11.4161, -30.4594],\n",
       "           [  9.5095,  -0.6160, -24.8739],\n",
       "           [ 18.0309,  12.0601, -32.3929]]]])]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "maps_per_group = int(len(activations[1]) / 2)\n",
    "#print(maps_per_group)\n",
    "activation_groups_layer_1 = torch.split(activations, 2, dim=1)\n",
    "activation_groups_layer_1 = list(activation_groups_layer_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[[[30.5966, 30.6605],\n",
       "           [24.3373, 29.2164]],\n",
       " \n",
       "          [[50.8009, 35.5511],\n",
       "           [23.6404, 38.5105]]],\n",
       " \n",
       " \n",
       "         [[[34.4659, 35.3320],\n",
       "           [49.9759, 29.8387]],\n",
       " \n",
       "          [[38.9041, 51.5231],\n",
       "           [75.1428, 32.3679]]]]), tensor([[[[ 4.7757, 30.9422],\n",
       "           [17.7242, -0.7584]],\n",
       " \n",
       "          [[19.6616, 23.5610],\n",
       "           [ 4.8597, 21.3619]]],\n",
       " \n",
       " \n",
       "         [[[35.0414, 33.5382],\n",
       "           [22.2364, 69.4363]],\n",
       " \n",
       "          [[42.2892, 21.2186],\n",
       "           [48.5784, 15.7545]]]]), tensor([[[[19.6616, 23.5610],\n",
       "           [ 4.8597, 21.3619]],\n",
       " \n",
       "          [[48.3828, 31.6299],\n",
       "           [ 6.2416, 37.1330]]],\n",
       " \n",
       " \n",
       "         [[[42.2892, 21.2186],\n",
       "           [48.5784, 15.7545]],\n",
       " \n",
       "          [[26.6290, 28.9950],\n",
       "           [63.7339, 11.0429]]]]), tensor([[[[49.5723, 32.5651],\n",
       "           [19.9215, 12.8028]]],\n",
       " \n",
       " \n",
       "         [[[47.9325, 20.1572],\n",
       "           [35.3421,  6.4070]]]])]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_groups_layer_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.empty(2)\n",
    "groupwise_activation_norms = torch.zeros_like(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (9) must match the size of tensor b (4) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f81e235d874b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mfirst_map_row_view\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0mcurrent_group_layer_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_of_map_layer_1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# shape: 1 X (Height * Width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mdifference_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_per_row_view\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_map_row_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mnumerator_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdifference_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mdenominator_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmap_per_row_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_map_row_view\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (9) must match the size of tensor b (4) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "for i in range(0, 2):\n",
    "    current_group = activation_groups[i]\n",
    "    current_group_layer_1 = activation_groups_layer_1[i]\n",
    "    \n",
    "    num = current_group.size(0) * current_group.size(1)\n",
    "    size_of_map = current_group.size(2) * current_group.size(3)\n",
    "    size_of_map_layer_1 = current_group_layer_1.size(2) * current_group_layer_1.size(3)\n",
    "    \n",
    "    map_per_row_view = current_group.contiguous().view(num, -1)       # shape: (Batches*Channels) X (Height * Width)\n",
    "    first_map_row_view =  current_group_layer_1[0][0].view(-1, size_of_map_layer_1)  # shape: 1 X (Height * Width)\n",
    "    \n",
    "    difference_tensor = torch.sub(map_per_row_view, first_map_row_view)\n",
    "    numerator_tensor = difference_tensor.norm(1, dim=1)\n",
    "    denominator_tensor = torch.add(map_per_row_view.norm(1, dim=1), first_map_row_view.norm(1))\n",
    "    groupwise_activation_norms[i] = torch.div(numerator_tensor, denominator_tensor).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 3, 3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_groups[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2, 2])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_groups_layer_1[i].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[30.5966, 30.6605],\n",
       "         [24.3373, 29.2164]]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_groups_layer_1[i][0][0].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying the activation norm across the whole batch now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 7, 3, 3])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.randn(3,2,5,5)\n",
    "activations = F.conv2d(inputs,mock_filter_combined)\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 2, 3, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_filter_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "maps_per_group = int(len(activations[1]) / 2)\n",
    "print(maps_per_group)\n",
    "activation_groups = torch.split(activations, 2, dim=1)\n",
    "activation_groups = list(activation_groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "torch.Size([3, 2, 3, 3])\n",
      "torch.Size([3, 2, 3, 3])\n",
      "torch.Size([3, 2, 3, 3])\n",
      "torch.Size([3, 1, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "print(len(activation_groups))\n",
    "for i in range(len(activation_groups)):\n",
    "    print(activation_groups[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 2])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [20.2044,  4.8905, -0.6969,  9.2941]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 4.4382, 16.1910, 25.1669,  2.5293]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [ 14.8858,  -7.3813, -12.8645,  22.1204]])\n",
      "torch.Size([2, 2, 2])\n",
      "tensor([[  0.0000,   0.0000,   0.0000,   0.0000],\n",
      "        [  7.2477, -12.3195,  26.3419, -53.6818]])\n",
      "tensor([0.2723, 0.8087])\n"
     ]
    }
   ],
   "source": [
    "# Testing for each image a neuron is chosen\n",
    "input = torch.empty(2)\n",
    "l1_norms = torch.zeros_like(input)\n",
    "for i in range(0, 2):\n",
    "    current_group = groups[i]\n",
    "    # print(current_group.size())\n",
    "    current_norm = torch.zeros(1)\n",
    "    for j in range(0, 2):\n",
    "        current_map_set = current_group[j]  \n",
    "        print(current_map_set.shape)\n",
    "        num = current_group.size(0)\n",
    "        # print(num)\n",
    "        sub_tensor = current_map_set.contiguous().view(num, -1)\n",
    "        # print(sub_tensor.shape)\n",
    "        sub_tensor_2 = current_map_set[0].view(-1,4)\n",
    "        # print(sub_tensor_2.shape)\n",
    "        difference_tensor = torch.sub(sub_tensor, sub_tensor_2)\n",
    "        print(difference_tensor)\n",
    "        num_tensor = difference_tensor.norm(1, dim=1)\n",
    "        denom_tensor = torch.add(sub_tensor.norm(1, dim=1), sub_tensor_2.norm(1))\n",
    "        value_tensor = torch.div(num_tensor, denom_tensor).norm(1)\n",
    "        current_norm = current_norm + value_tensor\n",
    "    l1_norms[i] = current_norm\n",
    "print(l1_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "groupwise norm tensor([0.2119, 0.2260])\n"
     ]
    }
   ],
   "source": [
    "## Testing for each batch a neuron is chosen\n",
    "input = torch.empty(2)\n",
    "l1_norms = torch.zeros_like(input)\n",
    "for i in range(0, 2):\n",
    "    current_group = activation_groups[i]\n",
    "    batch_size = current_group.shape[0]\n",
    "    first_filter_maps = current_group[:,0, :].unsqueeze(1)\n",
    "    difference_tensor = torch.sub(current_group, first_filter_maps)\n",
    "    difference_tensor = difference_tensor.contiguous().view(-1, \n",
    "                                                    difference_tensor.shape[2] * difference_tensor.shape[3])\n",
    "    num_tensor_norm = difference_tensor.norm(1, dim=1)\n",
    "    first_filter_map_view = first_filter_maps.view(first_filter_maps.shape[0], first_filter_maps.shape[1], \n",
    "                                                    first_filter_maps.shape[2] * first_filter_maps.shape[3])\n",
    "    first_filter_map_norms = first_filter_map_view.norm(1, dim=2)\n",
    "    current_group_view = current_group.view(current_group.shape[0], current_group.shape[1],\n",
    "                                           current_group.shape[2] * current_group.shape[3])\n",
    "    current_group_norms = current_group_view.norm(1, dim=2)\n",
    "    denom_tensor_part = torch.add(first_filter_map_norms, current_group_norms)\n",
    "    denom_tensor_part_view = denom_tensor_part.view(-1)\n",
    "    denom_tensor_norm = torch.add(denom_tensor_part_view, \n",
    "                            num_tensor_norm)\n",
    "    iou_map_wise = torch.div(num_tensor_norm, denom_tensor_norm)\n",
    "    l1_norms[i] = torch.div(iou_map_wise.norm(1), batch_size)\n",
    "\n",
    "print('groupwise norm', l1_norms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-67.7866, -36.9191,  -6.2290],\n",
       "          [-23.5829, -13.4695,  19.0742],\n",
       "          [-25.3497,  -0.2510,   7.3293]],\n",
       "\n",
       "         [[-43.3271, -21.6196,  -9.9934],\n",
       "          [ -7.0702,  -5.8806,  15.7523],\n",
       "          [-22.9951,   1.1625,   7.7530]]],\n",
       "\n",
       "\n",
       "        [[[  3.4329,  26.4536,  23.8332],\n",
       "          [ 23.2319,  17.8439, -12.1644],\n",
       "          [ 33.1252,  20.0323,  -7.3384]],\n",
       "\n",
       "         [[ 34.4724,  14.1175,  20.4639],\n",
       "          [  9.6271,   7.5668,  -4.6012],\n",
       "          [ 22.5306,  -0.2863, -13.5641]]],\n",
       "\n",
       "\n",
       "        [[[  9.8017, -14.3055, -13.7639],\n",
       "          [ 15.8588,  10.2939, -13.9373],\n",
       "          [  7.6307,  -4.1720, -16.0641]],\n",
       "\n",
       "         [[  0.1219, -11.6931, -13.4266],\n",
       "          [  4.0194,  -1.0104, -12.8587],\n",
       "          [  9.6970, -15.2968, -18.2286]]]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = torch.Tensor(2,2,3,3)\n",
    "# print('a:', a)\n",
    "# b = a[:,0,:,:].unsqueeze(1)\n",
    "# print('shape of b:', b.shape)\n",
    "# print('b:', b)\n",
    "# c = torch.sub(b, a)\n",
    "\n",
    "# print('c shape:', c.shape)\n",
    "# print('c:', c[:,0,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([2,3,4])\n",
    "c = a.norm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 3, 3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_groups[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1, 3, 3])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_group = torch.stack(activation_groups[:2], dim=0)\n",
    "current_group.shape\n",
    "first_filter_maps = current_group[:,:, 0, :, :].unsqueeze(2)\n",
    "first_filter_maps.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing two neurons from different group and same groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-70-5622b700027a>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-70-5622b700027a>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "def purely_diff_based_measure(unit_x, unit_y, feature_maps):\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 2, 3, 3])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mock_filter_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(2,2,4,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.5040e-01, -4.4165e-01,  1.4327e-03,  2.1075e+00],\n",
       "          [-2.3981e-01,  1.8919e-01,  1.7837e+00, -1.4799e+00],\n",
       "          [ 5.8161e-01,  1.2003e+00, -1.7110e+00, -2.2401e+00],\n",
       "          [ 8.5365e-01,  1.6133e+00, -1.2795e+00,  6.5067e-01]],\n",
       "\n",
       "         [[ 1.4395e+00,  8.0146e-01,  9.5984e-01,  1.0663e-01],\n",
       "          [-1.9015e+00, -2.8028e-01,  1.0168e+00,  4.1139e-01],\n",
       "          [ 4.2417e-01, -9.0444e-01,  1.7127e+00,  2.9496e-01],\n",
       "          [ 3.1056e-01, -3.4820e-01, -1.1773e+00, -8.3922e-01]]],\n",
       "\n",
       "\n",
       "        [[[ 2.1817e+00, -1.1511e+00,  5.6999e-01, -8.4488e-01],\n",
       "          [ 1.0534e+00, -3.3193e-01, -2.2796e+00, -2.9017e-02],\n",
       "          [-1.2312e+00, -1.8102e+00,  1.6412e+00, -4.6015e-02],\n",
       "          [-1.7093e+00, -6.1592e-01, -2.5223e-01,  6.7079e-01]],\n",
       "\n",
       "         [[ 1.9713e-01,  1.4443e+00, -8.5217e-01,  3.4045e-01],\n",
       "          [ 4.4652e-01, -2.7655e+00,  5.9683e-01, -1.8310e-01],\n",
       "          [ 1.3856e+00, -1.6020e+00, -1.5165e+00, -1.7883e+00],\n",
       "          [ 1.9327e+00,  4.7155e-01,  4.8482e-01,  1.0525e+00]]]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 2, 2])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = F.conv2d(inputs,mock_filter_combined)\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 20.3447,  -3.6006],\n",
       "          [ -0.1327, -15.8012]],\n",
       "\n",
       "         [[ 27.2259,  27.0315],\n",
       "          [ 14.4511, -13.8277]],\n",
       "\n",
       "         [[ 13.3662,   2.1523],\n",
       "          [ 26.7683,  -6.2244]],\n",
       "\n",
       "         [[ 24.8469,  18.0259],\n",
       "          [ 15.8077, -24.5976]],\n",
       "\n",
       "         [[ 24.8469,  18.0259],\n",
       "          [ 15.8077, -24.5976]],\n",
       "\n",
       "         [[  9.7275,  21.4245],\n",
       "          [ -0.2310, -10.9674]],\n",
       "\n",
       "         [[ 31.4743,   8.4767],\n",
       "          [  3.8633, -10.3287]]],\n",
       "\n",
       "\n",
       "        [[[-37.0816, -49.0371],\n",
       "          [-16.9035,  -7.6240]],\n",
       "\n",
       "         [[-54.8978, -51.6846],\n",
       "          [-57.0522, -11.3033]],\n",
       "\n",
       "         [[-17.4338, -53.6368],\n",
       "          [ -6.7704, -41.0864]],\n",
       "\n",
       "         [[-37.9405, -12.0334],\n",
       "          [-22.2386, -20.6954]],\n",
       "\n",
       "         [[-37.9405, -12.0334],\n",
       "          [-22.2386, -20.6954]],\n",
       "\n",
       "         [[-32.7216, -39.6424],\n",
       "          [-35.6666,  -1.4720]],\n",
       "\n",
       "         [[ -8.8883, -21.9993],\n",
       "          [-25.6879, -20.9507]]]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'std_map_wise' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-76-819d05cf8f49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstd_map_wise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'std_map_wise' is not defined"
     ]
    }
   ],
   "source": [
    "std_map_wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 24.8469,  18.0259],\n",
       "         [ 15.8077, -24.5976]],\n",
       "\n",
       "        [[-37.9405, -12.0334],\n",
       "         [-22.2386, -20.6954]]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_x = 0\n",
    "unit_y = 1\n",
    "act_unit_x = activations[:, unit_x]\n",
    "act_unit_y = activations[:, unit_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 20.3447,  -3.6006],\n",
       "         [ -0.1327, -15.8012]],\n",
       "\n",
       "        [[-37.0816, -49.0371],\n",
       "         [-16.9035,  -7.6240]]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_unit_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 27.2259,  27.0315],\n",
       "         [ 14.4511, -13.8277]],\n",
       "\n",
       "        [[-54.8978, -51.6846],\n",
       "         [-57.0522, -11.3033]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_unit_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_unit_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_maps = activations.size(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "number_of_maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_map_wise = activations.transpose(0, 1).contiguous().view(number_of_maps, -1).std(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_map_wise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 20.3447,  -3.6006],\n",
       "          [ -0.1327, -15.8012]],\n",
       "\n",
       "         [[ 27.2259,  27.0315],\n",
       "          [ 14.4511, -13.8277]],\n",
       "\n",
       "         [[ 13.3662,   2.1523],\n",
       "          [ 26.7683,  -6.2244]],\n",
       "\n",
       "         [[ 24.8469,  18.0259],\n",
       "          [ 15.8077, -24.5976]],\n",
       "\n",
       "         [[ 24.8469,  18.0259],\n",
       "          [ 15.8077, -24.5976]],\n",
       "\n",
       "         [[  9.7275,  21.4245],\n",
       "          [ -0.2310, -10.9674]],\n",
       "\n",
       "         [[ 31.4743,   8.4767],\n",
       "          [  3.8633, -10.3287]]],\n",
       "\n",
       "\n",
       "        [[[-37.0816, -49.0371],\n",
       "          [-16.9035,  -7.6240]],\n",
       "\n",
       "         [[-54.8978, -51.6846],\n",
       "          [-57.0522, -11.3033]],\n",
       "\n",
       "         [[-17.4338, -53.6368],\n",
       "          [ -6.7704, -41.0864]],\n",
       "\n",
       "         [[-37.9405, -12.0334],\n",
       "          [-22.2386, -20.6954]],\n",
       "\n",
       "         [[-37.9405, -12.0334],\n",
       "          [-22.2386, -20.6954]],\n",
       "\n",
       "         [[-32.7216, -39.6424],\n",
       "          [-35.6666,  -1.4720]],\n",
       "\n",
       "         [[ -8.8883, -21.9993],\n",
       "          [-25.6879, -20.9507]]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_fields = activations.transpose(1, 3).div(std_map_wise).transpose(1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 2, 2])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive_fields.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.9381, -0.1660],\n",
       "          [-0.0061, -0.7286]],\n",
       "\n",
       "         [[ 0.7535,  0.7482],\n",
       "          [ 0.4000, -0.3827]],\n",
       "\n",
       "         [[ 0.5004,  0.0806],\n",
       "          [ 1.0021, -0.2330]],\n",
       "\n",
       "         [[ 1.0565,  0.7665],\n",
       "          [ 0.6721, -1.0459]],\n",
       "\n",
       "         [[ 1.0565,  0.7665],\n",
       "          [ 0.6721, -1.0459]],\n",
       "\n",
       "         [[ 0.4297,  0.9463],\n",
       "          [-0.0102, -0.4844]],\n",
       "\n",
       "         [[ 1.6320,  0.4395],\n",
       "          [ 0.2003, -0.5356]]],\n",
       "\n",
       "\n",
       "        [[[-1.7099, -2.2612],\n",
       "          [-0.7795, -0.3516]],\n",
       "\n",
       "         [[-1.5194, -1.4305],\n",
       "          [-1.5790, -0.3128]],\n",
       "\n",
       "         [[-0.6526, -2.0079],\n",
       "          [-0.2535, -1.5381]],\n",
       "\n",
       "         [[-1.6132, -0.5117],\n",
       "          [-0.9456, -0.8800]],\n",
       "\n",
       "         [[-1.6132, -0.5117],\n",
       "          [-0.9456, -0.8800]],\n",
       "\n",
       "         [[-1.4453, -1.7510],\n",
       "          [-1.5754, -0.0650]],\n",
       "\n",
       "         [[-0.4609, -1.1407],\n",
       "          [-1.3320, -1.0864]]]])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "receptive_fields = torch.sigmoid(receptive_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.7187, 0.4586],\n",
       "          [0.4985, 0.3255]],\n",
       "\n",
       "         [[0.6799, 0.6788],\n",
       "          [0.5987, 0.4055]],\n",
       "\n",
       "         [[0.6225, 0.5201],\n",
       "          [0.7315, 0.4420]],\n",
       "\n",
       "         [[0.7420, 0.6828],\n",
       "          [0.6620, 0.2600]],\n",
       "\n",
       "         [[0.7420, 0.6828],\n",
       "          [0.6620, 0.2600]],\n",
       "\n",
       "         [[0.6058, 0.7204],\n",
       "          [0.4974, 0.3812]],\n",
       "\n",
       "         [[0.8364, 0.6082],\n",
       "          [0.5499, 0.3692]]],\n",
       "\n",
       "\n",
       "        [[[0.1532, 0.0944],\n",
       "          [0.3144, 0.4130]],\n",
       "\n",
       "         [[0.1795, 0.1930],\n",
       "          [0.1709, 0.4224]],\n",
       "\n",
       "         [[0.3424, 0.1184],\n",
       "          [0.4370, 0.1768]],\n",
       "\n",
       "         [[0.1661, 0.3748],\n",
       "          [0.2798, 0.2932]],\n",
       "\n",
       "         [[0.1661, 0.3748],\n",
       "          [0.2798, 0.2932]],\n",
       "\n",
       "         [[0.1907, 0.1479],\n",
       "          [0.1715, 0.4838]],\n",
       "\n",
       "         [[0.3868, 0.2422],\n",
       "          [0.2088, 0.2523]]]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive_fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_x = 0\n",
    "unit_y = 1\n",
    "act_unit_x = receptive_fields[:, unit_x]\n",
    "act_unit_y = receptive_fields[:, unit_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_unit_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7187, 0.4586],\n",
       "         [0.4985, 0.3255]],\n",
       "\n",
       "        [[0.1532, 0.0944],\n",
       "         [0.3144, 0.4130]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_unit_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6799, 0.6788],\n",
       "         [0.5987, 0.4055]],\n",
       "\n",
       "        [[0.1795, 0.1930],\n",
       "         [0.1709, 0.4224]]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_unit_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_tensor = act_unit_x - act_unit_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_prod = torch.mul(act_unit_x, act_unit_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4887, 0.3113],\n",
       "         [0.2984, 0.1320]],\n",
       "\n",
       "        [[0.0275, 0.0182],\n",
       "         [0.0537, 0.1745]]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hadamard_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0388, -0.2202],\n",
       "         [-0.1002, -0.0800]],\n",
       "\n",
       "        [[-0.0264, -0.0986],\n",
       "         [ 0.1435, -0.0094]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.7171)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_tensor.norm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.5043)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hadamard_prod.norm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = (2 * difference_tensor.norm(1)) / (act_unit_x.norm(1) + act_unit_y.norm(1) + difference_tensor.norm(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2042)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1195, -0.1626],\n",
      "         [ 0.0695,  0.1820]],\n",
      "\n",
      "        [[ 0.1763, -0.2564],\n",
      "         [ 0.1572, -0.1164]]])\n"
     ]
    }
   ],
   "source": [
    "unit_x = 2\n",
    "unit_y = 3\n",
    "act_unit_x = receptive_fields[:, unit_x]\n",
    "act_unit_y = receptive_fields[:, unit_y]\n",
    "difference_tensor = act_unit_x - act_unit_y\n",
    "hadamard_prod = torch.mul(act_unit_x, act_unit_y)\n",
    "print(difference_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2398)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_tensor.norm(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4619, 0.3551],\n",
       "         [0.4842, 0.1149]],\n",
       "\n",
       "        [[0.0569, 0.0444],\n",
       "         [0.1223, 0.0518]]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hadamard_prod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = (2 * difference_tensor.norm(1)) / (act_unit_x.norm(1) + act_unit_y.norm(1) + difference_tensor.norm(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3065)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 7, 2, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "receptive_fields.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "unit_x = np.array([0 ,2])\n",
    "unit_y = np.array([1 ,3])\n",
    "\n",
    "act_unit_x = receptive_fields[:, unit_x]\n",
    "act_unit_y = receptive_fields[:, unit_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.7187, 0.4586],\n",
       "         [0.4985, 0.3255]],\n",
       "\n",
       "        [[0.1532, 0.0944],\n",
       "         [0.3144, 0.4130]]])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_unit_x[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6799, 0.6788],\n",
       "         [0.5987, 0.4055]],\n",
       "\n",
       "        [[0.1795, 0.1930],\n",
       "         [0.1709, 0.4224]]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "act_unit_y[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "difference_tensor = act_unit_x - act_unit_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0388, -0.2202],\n",
       "         [-0.1002, -0.0800]],\n",
       "\n",
       "        [[-0.0264, -0.0986],\n",
       "         [ 0.1435, -0.0094]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_tensor[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1195, -0.1626],\n",
       "         [ 0.0695,  0.1820]],\n",
       "\n",
       "        [[ 0.1763, -0.2564],\n",
       "         [ 0.1572, -0.1164]]])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_tensor[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "hadamard_tensor = torch.mul(act_unit_x, act_unit_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4887, 0.3113],\n",
       "         [0.2984, 0.1320]],\n",
       "\n",
       "        [[0.0275, 0.0182],\n",
       "         [0.0537, 0.1745]]])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hadamard_tensor[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = []\n",
    "for i in range(len(unit_x)):\n",
    "    score.append((2 * difference_tensor[:,i].norm(1)) \n",
    "                 / (act_unit_x[:, i].norm(1) + act_unit_y[:, i].norm(1) + difference_tensor[:,i].norm(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2, 2])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "difference_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2042, 0.3065])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor(0.2042), tensor(0.3065)]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R3 Activation Norm Spatially concentrate the activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "inputs = torch.randn(2,2,5,5)\n",
    "activations = F.conv2d(inputs,mock_filter_combined)\n",
    "print(activations.shape)\n",
    "batch_size = activations.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = np.indices((activations.shape[2], activations.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "indices = torch.Tensor(indices)\n",
    "print(indices.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_coordinates = indices[1]\n",
    "y_coordinates = indices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [0., 1., 2.],\n",
       "        [0., 1., 2.]])"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [1., 1., 1.],\n",
       "        [2., 2., 2.]])"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 7])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([14])"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_sums = torch.sum(activations,(2,3))\n",
    "print(activation_sums.size())\n",
    "activation_sums = activation_sums.view(-1)\n",
    "activation_sums.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_centers = torch.mul(x_coordinates, activations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_centers = torch.sum(x_centers, (2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14])"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_centers = x_centers.view(-1)\n",
    "x_centers = torch.div(x_centers, activation_sums)\n",
    "x_centers.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14])"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_centers = torch.mul(y_coordinates, activations)\n",
    "y_centers = torch.sum(y_centers, (2,3))\n",
    "y_centers = y_centers.view(-1)\n",
    "y_centers = torch.div(y_centers, activation_sums)\n",
    "y_centers.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 3, 3])\n",
      "torch.Size([14, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "x_centers.unsqueeze_(1).unsqueeze_(1)\n",
    "x_coordinates_expand = x_coordinates.expand(14,3,3)\n",
    "print(x_coordinates_expand.shape)\n",
    "print(x_centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 3, 3])\n",
      "torch.Size([14, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "y_centers.unsqueeze_(1).unsqueeze_(1)\n",
    "y_coordinates_expand = y_coordinates.expand(14,3,3)\n",
    "print(y_coordinates_expand.shape)\n",
    "print(y_centers.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([14, 3, 3])\n",
      "torch.Size([14, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "x_deviations = torch.sub(x_coordinates_expand,x_centers)\n",
    "x_deviations = torch.pow(x_deviations, 2)\n",
    "print(x_deviations.shape)\n",
    "\n",
    "y_deviations = torch.sub(y_coordinates_expand, y_centers)\n",
    "y_deviations = torch.pow(y_deviations, 2)\n",
    "print(y_deviations.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 3, 3])"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_part_1 = torch.pow(torch.add(x_deviations, y_deviations), 0.5)\n",
    "num_part_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 3, 3])"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activations = activations.view(-1,activations.shape[2],activations.shape[3])\n",
    "activations.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14, 3, 3])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = torch.mul(activations, num_part_1)\n",
    "num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([14])"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num = torch.sum(num,(1,2))\n",
    "num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-1.3242)"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = torch.div(num, activation_sums)\n",
    "score = torch.div(score.sum(), batch_size)\n",
    "score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "# whole function at once activations pf size N x C x F_l x F_l\n",
    "batch_size = activations.shape[0] \n",
    "indices = np.indices((activations.shape[2], activations.shape[3])) #2 x F_l x F_l\n",
    "indices = torch.Tensor(indices)\n",
    "x_coordinates = indices[1]          # F_l x F_l\n",
    "y_coordinates = indices[0]          # F_l x F_l\n",
    "activation_sums = torch.sum(activations,(2,3))       # N x C\n",
    "activation_sums = activation_sums.view(-1)           # N * C\n",
    "\n",
    "x_centers = torch.mul(x_coordinates, activations)    # N x C x F_l x F_l \n",
    "x_centers = torch.sum(x_centers, (2,3))              # N x C\n",
    "x_centers = x_centers.view(-1)                       # N*C\n",
    "x_centers = torch.div(x_centers, activation_sums)    # N*C\n",
    "\n",
    "y_centers = torch.mul(y_coordinates, activations)\n",
    "y_centers = torch.sum(y_centers, (2,3))\n",
    "y_centers = y_centers.view(-1)\n",
    "y_centers = torch.div(y_centers, activation_sums)    # N*C\n",
    "\n",
    "x_centers.unsqueeze_(1).unsqueeze_(1)\n",
    "x_coordinates_expand = x_coordinates.expand(14,3,3)\n",
    "y_centers.unsqueeze_(1).unsqueeze_(1)\n",
    "y_coordinates_expand = y_coordinates.expand(14,3,3)\n",
    "\n",
    "x_deviations = torch.sub(x_coordinates_expand,x_centers)\n",
    "x_deviations = torch.pow(x_deviations, 2)\n",
    "y_deviations = torch.sub(y_coordinates_expand, y_centers)\n",
    "y_deviations = torch.pow(y_deviations, 2)                 # N*C x F_l x F_l\n",
    "\n",
    "num_part_1 = torch.pow(torch.add(x_deviations, y_deviations), 0.5)\n",
    "activations = activations.view(-1,activations.shape[2],activations.shape[3]) # N*C x F_l x F_l\n",
    "num = torch.mul(activations, num_part_1)\n",
    "num = torch.sum(num,(1,2))     # N*C       \n",
    "score = torch.div(num, activation_sums)\n",
    "score = torch.div(score.sum(), batch_size)   # 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.2960)"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-58.5977, -53.1712, -29.2761, -15.2708, -15.2708, -49.5474,  -7.5840,\n",
       "         53.8446,  30.4071, 120.9402,  23.1874,  23.1874,  30.7302, -33.4064])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_sums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-57.5977, -52.1712, -28.2761, -14.2708, -14.2708, -48.5474,  -6.5840,\n",
       "         54.8446,  31.4071, 121.9402,  24.1874,  24.1874,  31.7302, -32.4064])"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "activation_sums + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
